# 基于语料库的大规模文本处理

# 1 语料库及其特征

**传统的句法-语义分析主要是基于规则的方法**。由于自然语言理解的复杂性，各种知识的数量巨大，而且具有高度的不确定性，利用规则不可能完全准确地表达理解自然语言所需的各种知识。单纯依靠规则的方法曾经使机器翻译一度陷入低谷。

20世纪90年代，**自然语言理解的研究在基于规则的技术中引入语料库的方法**，其中包括统计方法、基于实例的方法和通过预料加工手段使语料库转化为语言知识库的方法等。

WordNet是1990年由Princeton大学的Miller等人设计和构造的。一部WordNet词典包含将近95600格词形（51500单词和44100搭配词）和70100个词义，分为名词、动词、形容词、副词和虚词5类。在WordNet词典中，**按语义而不是按词性来组织词汇信息**，名词有5700个，含有48800个同义词集，分成25类文件，平均深度12层。最高层为根概念，不含有固有名词。

普通词典中遗漏的大部分是构造性信息而不是事实性的信息。

WordNet是按一定结构组织起来的语义类词典，不要特征如下：

- 整个名词组成一个继承关系。
  - WordNet有着严格的层次关系，一个单词可以把它所有前辈的一般性的上位词的信息都继承下来，可以提供全局性的语义关系，具有IS-A关系。
- 动词是一个语义网。
  - 表达动词的含义对任何词汇语言学来说都是困难的。WordNet不进行成分分析，而是进行关系分析，讨论动词间的纵向关系，即词汇蕴含关系。

为了研究自然语言理解，首先需要研究大规模真实语料库的建立和大规模、信息丰富的机读词典的编制方法。规模为几万、十几万甚至是几十万的词，含有丰富的信息（如包含词的搭配信息、文法信息等）的计算机可用词典，是自然语言处理系统的基础。需要深入研究采用什么样的词典结构、包含词的那些信息、如和对词进行选择、如何以大规模语料为资料建立词典，即如何从大规模预料中获取词等。

书面汉语不同于英语、法语、德语等印欧语言，词与词之间没有空格。在汉语自然语言处理中，凡是设计句法、语义的研究，都要以词为基本单位来进行。词是汉语文法和语义研究的中心问题，也是汉语自然语言处理的关键问题。目前，对大规模汉语语料库的加工主要包括自动分词和标注，标注又包括词性标注和词义标注。

# 2 汉语自动分词方法

汉语的自动分词方法主要以基于词典的机械匹配分词方法为主。最大匹配法、逆向最大匹配法、逐词遍历匹配法是最基本的机械式切词方法，还有一些方法都是在这三种方法基础上的改进，比如双向扫描法、设立切分标志法及最佳匹配法等。

近年来，也有人提出无词典分词方法、基于专家系统和人工神经网络的分词方法。

汉语分词是汉语自然语言理解的关键。目前汉语分词技术距实际应用的要求还有很大距离。主要原因是再分词时，语言学家靠的是“语感”，没有什么形式的定义。分词过程中经常出现歧义。

## 2.1 最大匹配法

最大匹配法（maximum matching method，简称MM法）也称为正向最大匹配法。

其**基本思想**是：在计算机中存放一个分词用词典，从待切分的文本中按自左到右的顺序截取一个定长的汉字串，通常为6至8个汉字（或长度为词典中最大词长），这个字符串的长度为最大词长。将这个具有最大词长的字符串和词典中词进行匹配，若匹配成功，则可确定这个字符串为词，计算机程序的指针向后移动与给定最大词长相应个数的汉字，继续进行匹配，否则，把该字符串从右边逐次减去一个汉字，再与词典中的词进行匹配，直到匹配成功为止。



## 2.2 逆向最大匹配法

逆向最大匹配法（reverse maximum macthing method，简称RMM法）的基本原理与MM法相同，所不同的是分词时对待切分文本的扫描方向。

RMM法从待切分文本中截取字符串的方向是从右到左。在与词典匹配不成功时，将所截取的汉字串从左至右逐次减去一个汉字，再与词典中的词进行匹配，直到匹配成功为止。

实验表明，RMM法的切词正确率要比MM法高。

## 2.3 逐词遍历匹配法

逐词遍历匹配法（word-for-word ergodic matching method）中存放的词按照由长到短的顺序，逐个与待切分的语料文本进行匹配，直到把文本中所有词都切分出来为止。

由于这种方法要把词典中的每一个词都匹配一遍，因此需要花费很多时间，算法的时间复杂度相应增加，切词速度较慢，切词效率不高。

# 3 汉语词性的标注方法

**词性标注**就是给定句子判定每个词的文法范畴，确定其词性并加以标注的过程。

设定词汇的词性时构造语段的基础，但是词性兼类是英汉机器翻译中典型的歧义现象，如果语料的词性能自动标注，那么歧义问题就好解决了。

在自然语言处理中，**研究词性自动标注的目的**主要是：

1. 为了对文本进行文法分析或句法分析等更高层次的文本加工提供基础，以便在文摘、自动校对、OCR识别后处理等应用系统开发中提高准确率。
2. 通过对标注过的语料进行统计分析等处理，可以抽取蕴含在文本中的语言知识，为语言学的研究提供可靠的数据，同时，又可以进一步运用这些知识，改进词性标注系统，提高词性标注系统的准确率。

词性标注的**难点**主要是兼类词的自动词类歧义排除。所谓**兼类词**是指那些具有两个或两个以上词性的词。由于汉语是一种没有词的形态的变化语言，词的类别不能像印欧语一样直接由词的形态来判断，再加上常用词的兼类现象严重等因素，因此，要确定一个词再文本中的词性有时是很困难的。

词性标注方法主要是兼类词的歧义排除方法。目前的方法主要由两大类：

- 基于概率统计模型词性标注方法
  - 代表性系统是CLAWS系统，它用统计模型来消除兼类词歧义，使自动标注的准确率达到96%。1988年，S.J.DeRose对CLAWS系统做了一些改进，利用线性规划方法降低系统的复杂性，提出了VOLSUNGA算法，大大提高了处理效率，使自动词性标注的达到了实用水平。
- 基于规则的词性标注方法
  - 代表系统使TAGGIT，它是Greene和Robin出于语言学的目的，于1977年设计的词性标注系统。该系统采用基于上下文框架规则的方法，使用了具有86个标记的标记集和用于排除兼类词歧义的3300条上下文框架规则，对美国的BROWN语料库进行标记，准确率为77%。1992年美国滨州大学Brill提出了一种基于转换的错误驱动学习机制，从带标语料库中自动获取转换规则以用于词性的自动标注，所建立的基于规则的词性标注系统的标注准确率大大提高，获得了于基于统计模型同样搞得准确率。

# 4 汉语词义标注方法

**词义标注**就是对文本中的每个词根据其所属上下文给出它的语义编码。这个编码可以使词典释义文本中的某个义项号，也可以是义类词典中相应的义类编码。

**自动词性标注**就是利用计算机通过逻辑推理机制，利用文本的上下文环境，对词的词义进行自动判断，选择词的某一正确义项并加以标注的过程。

词义标注的**难点**是对词的歧义排除。在各种语言中，一词多义的现象普遍存在，要确定一个词的词义一定要依据上下文环境。

目前，**多义词的歧义排除方法的研究尚处于初级阶段**。近几年来，由于统计概率模型在词性标注方面的成功以及计算机网络技术的发展，越来越多的研究转向了基于语料库的概率统计方法。